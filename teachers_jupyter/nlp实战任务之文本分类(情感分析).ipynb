{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a405cda2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:53:55.068182Z",
     "start_time": "2023-02-25T08:53:53.640997Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistilBertTokenizerFast(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 7592, 1010, 3071, 1010, 2651, 2003, 1037, 2204, 2154, 102], [101, 2129, 2024, 2017, 1010, 2986, 4067, 2017, 1010, 1998, 2017, 1029, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', use_fast=True)\n",
    "\n",
    "print(tokenizer)\n",
    "# 编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    'hello, everyone, today is a good day',\n",
    "    'how are you , fine thank you , and you?'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a69a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:40.603391Z",
     "start_time": "2023-02-25T09:02:35.691520Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/SupercoldZzz/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d4236b0cdc400db351341351222879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(path='glue', name='cola')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd41ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T08:59:03.967473Z",
     "start_time": "2023-02-25T08:59:03.962486Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "818c3221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:02:46.570440Z",
     "start_time": "2023-02-25T09:02:45.964060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d555a417e0d3498084db63ad5a031268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d68249308564e91a79adf149650e4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481fcbc7d8ae45b3ad156455188a49ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(examples, tokenizer):\n",
    "    return tokenizer.batch_encode_plus(examples['sentence'], truncation=True)\n",
    "\n",
    "dataset = dataset.map(f,\n",
    "                     batched=True,\n",
    "                     batch_size=1000,\n",
    "                      # num_proc=1更快, 数据量不多的时候, 创建进程也是需要时间开销的.\n",
    "                     num_proc=1,\n",
    "                     remove_columns=['sentence', 'idx'],\n",
    "                     fn_kwargs={'tokenizer': tokenizer})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab49be03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:03:35.603371Z",
     "start_time": "2023-02-25T09:03:35.594395Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 1, 'input_ids': [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d10076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:04:17.844459Z",
     "start_time": "2023-02-25T09:04:16.977774Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.data.data_collator import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf242a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:06:12.322451Z",
     "start_time": "2023-02-25T09:06:12.312477Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset['train'],\n",
    "    batch_size=8,\n",
    "    collate_fn=DataCollatorWithPadding(tokenizer),\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "for data in loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dde3f719",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:06:20.000926Z",
     "start_time": "2023-02-25T09:06:19.985965Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1996,  2062,  4180,  2098,  2057, 14688,  2000,  2022,  1010,\n",
       "          1996,  2062,  2057,  3473,  4854,  2012,  1996,  7435,  1012,   102],\n",
       "        [  101,  2040, 17749,  2073,  2057,  4149,  2054,  1029,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 18500,  2245,  2008,  2002,  2001,  1996,  3159,  1997,  4768,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  1996,  4020,  2045, 28374,  1037,  2543,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2198, 14140,  2070,  2769,  1999,  1996,  2924,  2006,  5958,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2320,  9965,  2187,  1010,  5965,  2150,  2035,  1996, 13675,\n",
       "         16103,  2121,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2023,  2311,  2288, 12283,  1998, 12283,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  3389,  2097,  2196,  2681,  1012,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d29608d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:06:49.805312Z",
     "start_time": "2023-02-25T09:06:49.794342Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96f2330f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:08:33.571995Z",
     "start_time": "2023-02-25T09:08:33.519136Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8770e48c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:13:03.816612Z",
     "start_time": "2023-02-25T09:13:02.294680Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5718aa91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:34:23.446599Z",
     "start_time": "2023-02-25T11:34:23.426650Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.fc = torch.nn.Sequential(torch.nn.Linear(768, 768),\n",
    "                                      torch.nn.ReLU(),\n",
    "                                      torch.nn.Dropout(p=0.2),\n",
    "                                      torch.nn.Linear(768, 2)\n",
    "                                     )\n",
    "        \n",
    "        parameters = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "        self.fc[0].load_state_dict(parameters.pre_classifier.state_dict())\n",
    "        self.fc[3].load_state_dict(parameters.classifier.state_dict())\n",
    "        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        logits = self.pretrained(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = logits.last_hidden_state[:, 0]\n",
    "        logits = self.fc(logits)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "#             print('logits: ', logits)\n",
    "#             print('labels: ', labels)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            \n",
    "        return {'loss': loss, 'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "593dc584",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:34:29.237119Z",
     "start_time": "2023-02-25T11:34:26.201234Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "addd9d30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:17:45.504679Z",
     "start_time": "2023-02-25T09:17:45.494705Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66955010\n"
     ]
    }
   ],
   "source": [
    "print(sum(i.numel() for i in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb379a40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:34:32.148337Z",
     "start_time": "2023-02-25T11:34:32.065558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6949, grad_fn=<NllLossBackward0>), torch.Size([8, 2]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(**data)\n",
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "554da945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T09:23:39.157340Z",
     "start_time": "2023-02-25T09:23:39.140385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  1996,  2062,  4180,  2098,  2057, 14688,  2000,  2022,  1010,\n",
       "          1996,  2062,  2057,  3473,  4854,  2012,  1996,  7435,  1012,   102],\n",
       "        [  101,  2040, 17749,  2073,  2057,  4149,  2054,  1029,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101, 18500,  2245,  2008,  2002,  2001,  1996,  3159,  1997,  4768,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  1999,  1996,  4020,  2045, 28374,  1037,  2543,  1012,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2198, 14140,  2070,  2769,  1999,  1996,  2924,  2006,  5958,\n",
       "          1012,   102,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2320,  9965,  2187,  1010,  5965,  2150,  2035,  1996, 13675,\n",
       "         16103,  2121,  1012,   102,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  2023,  2311,  2288, 12283,  1998, 12283,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "        [  101,  3389,  2097,  2196,  2681,  1012,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d97ef9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:32:42.830551Z",
     "start_time": "2023-02-25T11:32:42.812599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': -1,\n",
       " 'input_ids': [101, 3021, 26265, 2627, 1996, 2160, 1012, 102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a18655fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:32:53.088132Z",
     "start_time": "2023-02-25T11:32:53.081151Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'input_ids': [101,\n",
       "  1996,\n",
       "  11279,\n",
       "  8469,\n",
       "  1996,\n",
       "  9478,\n",
       "  3154,\n",
       "  1997,\n",
       "  1996,\n",
       "  5749,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c2b3534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:34:36.308217Z",
     "start_time": "2023-02-25T11:34:36.293258Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    \n",
    "    loader_test = torch.utils.data.DataLoader(\n",
    "        dataset=dataset['validation'],\n",
    "        batch_size=16,\n",
    "        collate_fn=DataCollatorWithPadding(tokenizer),\n",
    "        shuffle=True,\n",
    "        drop_last=True\n",
    "    )\n",
    "    \n",
    "    outs = []\n",
    "    labels = []\n",
    "    for i, data in enumerate(loader_test):\n",
    "#         print(data)\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "            \n",
    "        outs.append(out['logits'].argmax(dim=1))\n",
    "        labels.append(data['labels'])\n",
    "        \n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if i == 50:\n",
    "            break\n",
    "            \n",
    "    outs = torch.cat(outs)\n",
    "    labels = torch.cat(labels)\n",
    "#     print('test labels:', labels)\n",
    "    accuracy = (outs == labels).sum().item() / len(labels)\n",
    "    print('accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a8008e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:34:46.712406Z",
     "start_time": "2023-02-25T11:34:38.947164Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "accuracy:  0.5502450980392157\n"
     ]
    }
   ],
   "source": [
    "test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3b1207ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:36:10.131937Z",
     "start_time": "2023-02-25T11:36:10.111988Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "905a9624",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:36:31.884870Z",
     "start_time": "2023-02-25T11:36:31.731280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ef42bd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:39:49.738016Z",
     "start_time": "2023-02-25T11:39:49.725051Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# 训练代码\n",
    "def train():\n",
    "    \n",
    "    # 定义优化器\n",
    "    optimizer = AdamW(model.parameters(), betas=(0.9, 0.999), eps=1e-8, lr=2e-5)\n",
    "    \n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                             num_warmup_steps=0,\n",
    "                             num_training_steps=len(loader),\n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for i, data in enumerate(loader):\n",
    "        input_ids, attention_mask, labels  = data['input_ids'], data['attention_mask'], data['labels']\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        out = model(input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    labels=labels)\n",
    "        loss = out['loss']\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            out = out['logits'].argmax(dim=1)\n",
    "            \n",
    "            accuracy = (labels==out).sum().item() / 8\n",
    "            \n",
    "            print(i, loss.item(), lr, accuracy)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "49beaf00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:40:40.693810Z",
     "start_time": "2023-02-25T11:39:53.129950Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\.venv\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6962183713912964 1.9981273408239703e-05 0.5\n",
      "\n",
      "50 0.377118319272995 1.9044943820224723e-05 0.875\n",
      "\n",
      "100 0.5701767206192017 1.810861423220974e-05 0.625\n",
      "\n",
      "150 0.3946194648742676 1.7172284644194758e-05 1.0\n",
      "\n",
      "200 0.5135958790779114 1.6235955056179777e-05 0.875\n",
      "\n",
      "250 0.8008895516395569 1.5299625468164797e-05 0.5\n",
      "\n",
      "300 0.7711583375930786 1.4363295880149814e-05 0.625\n",
      "\n",
      "350 0.5669834017753601 1.3426966292134834e-05 0.75\n",
      "\n",
      "400 0.4095596373081207 1.2490636704119851e-05 0.875\n",
      "\n",
      "450 0.4815349578857422 1.155430711610487e-05 0.75\n",
      "\n",
      "500 0.3883439302444458 1.0617977528089888e-05 0.75\n",
      "\n",
      "550 0.23434026539325714 9.681647940074908e-06 0.875\n",
      "\n",
      "600 0.31013554334640503 8.745318352059925e-06 0.875\n",
      "\n",
      "650 0.3703773021697998 7.808988764044945e-06 0.875\n",
      "\n",
      "700 0.23676088452339172 6.872659176029963e-06 0.875\n",
      "\n",
      "750 0.4773671627044678 5.936329588014982e-06 0.875\n",
      "\n",
      "800 0.4274585247039795 5e-06 0.75\n",
      "\n",
      "850 0.6012129187583923 4.063670411985019e-06 0.875\n",
      "\n",
      "900 0.20150703191757202 3.1273408239700374e-06 1.0\n",
      "\n",
      "950 0.45682013034820557 2.1910112359550564e-06 0.75\n",
      "\n",
      "1000 0.5870674848556519 1.2546816479400751e-06 0.625\n",
      "\n",
      "1050 0.234685480594635 3.183520599250937e-07 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05e7b51a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T11:41:56.611873Z",
     "start_time": "2023-02-25T11:41:48.502551Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "accuracy:  0.7781862745098039\n"
     ]
    }
   ],
   "source": [
    "test(model.to('cpu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
