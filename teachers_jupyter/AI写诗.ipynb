{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a54701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主要使用transformers库。 \n",
    "# 框架主要使用pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adacf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理数据 中文字符---》 数字\n",
    "# 创建数据集。 把处理好的数据变成pytorch的数据集。 \n",
    "# 生成模型， 有了transformers库， 一般不需要自己创建模型。\n",
    "# 训练预测过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd515b",
   "metadata": {},
   "source": [
    "### 处理数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1919c521",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:34:51.920761Z",
     "start_time": "2023-12-25T18:34:51.905800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 配置代理\n",
    "import os\n",
    "\n",
    "os.environ['http_proxy'] = '127.0.0.1:10809'\n",
    "os.environ['https_proxy'] = '127.0.0.1:10809'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb40b74e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:34:17.999022Z",
     "start_time": "2023-12-25T18:34:06.478834Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0ac7ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:34:55.966196Z",
     "start_time": "2023-12-25T18:34:54.560427Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('uer/gpt2-chinese-cluecorpussmall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2c3d845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:34:58.787107Z",
     "start_time": "2023-12-25T18:34:58.764169Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/gpt2-chinese-cluecorpussmall', vocab_size=21128, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f53f6ca4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:01.232891Z",
     "start_time": "2023-12-25T18:35:01.214939Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 3209, 3308, 7731, 886, 1355, 117, 671, 1915, 5185, 2519, 6151, 119, 5162, 2797, 2853, 7151, 1107, 117, 6929, 1838, 2828, 1198, 1143, 119, 6161, 5361, 2164, 6823, 6887, 117, 1126, 3189, 1168, 707, 3826, 119, 102], [101, 7270, 2128, 671, 4275, 3299, 117, 674, 2787, 2941, 6132, 1898, 119, 4904, 7599, 1430, 679, 2226, 117, 2600, 3221, 4373, 1068, 2658, 119, 862, 3189, 2398, 5529, 5989, 117, 5679, 782, 5387, 6823, 2519, 119, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 编码试算\n",
    "tokenizer.batch_encode_plus([\n",
    "    '明朝驿使发,一夜絮征袍.素手抽针冷,那堪把剪刀.裁缝寄远道,几日到临洮.',\n",
    "    '长安一片月,万户捣衣声.秋风吹不尽,总是玉关情.何日平胡虏,良人罢远征.'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "999a1679",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:10.874103Z",
     "start_time": "2023-12-25T18:35:04.365512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304752, '欲出未出光辣达,千山万山如火发.须臾走向天上来,逐却残星赶却月.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        with open('chinese_poems.txt', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        lines = [i.strip() for i in lines]\n",
    "        \n",
    "        self.lines = lines\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.lines[i]\n",
    "    \n",
    "dataset = Dataset()\n",
    "len(dataset), dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "836c240b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:10.890061Z",
     "start_time": "2023-12-25T18:35:10.876098Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    # 把中文编码成数字\n",
    "    data = tokenizer.batch_encode_plus(batch, padding=True, \n",
    "                               truncation=True,\n",
    "                               max_length=512,\n",
    "                               return_tensors='pt')\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae51f8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:10.905021Z",
     "start_time": "2023-12-25T18:35:10.892059Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=4,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98fe3a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:12.156672Z",
     "start_time": "2023-12-25T18:35:12.130742Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac0d6a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-23T19:24:02.687609Z",
     "start_time": "2023-12-23T19:24:02.669535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316724dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:14.340832Z",
     "start_time": "2023-12-25T18:35:14.313903Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 4819, 5285, 5021, 2419, 1874, 2798, 2397,  117, 4635, 4373, 3517,\n",
       "          704, 7755, 2347, 2170,  119, 3801, 2226, 2496, 2399, 5468, 7744, 2145,\n",
       "          117, 5825, 5709, 3198, 5688, 4324, 3341, 4692,  119,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 6505, 3482, 2231, 1064, 2552, 3815, 6565,  117, 4373,  100, 6574,\n",
       "         1064, 7032,  868, 1898,  119, 5696, 5900, 1094, 1064, 4324, 4989,  117,\n",
       "          877, 2140, 4466, 1064, 5364, 5290,  119, 5529, 2891, 2891, 1064, 4767,\n",
       "         1351,  117, 3309, 2259, 3241, 1064, 4685, 2127,  119, 4741,  921, 4706,\n",
       "         1064, 5439,  682,  117, 5632, 2552, 4761, 1064, 1780,  719,  119, 2516,\n",
       "         2398, 3787, 1064, 3481, 4895, 4989,  117, 5290, 1501, 5018, 1064, 5384,\n",
       "         4508,  734,  119, 1434,  862, 1628, 1064,  100,  792,  117, 2123,  680,\n",
       "         3734, 1064, 1398, 4619,  119, 4433,  741, 1064, 2340, 1381,  117, 7991,\n",
       "         7911, 1064, 1184, 1400,  119,  100, 7481, 1064, 2286, 2318,  117, 2563,\n",
       "         6241, 1064,  671, 5010,  119, 3805, 2255, 1064, 7478, 1920,  117, 2891,\n",
       "         4767, 1064, 7478, 2207,  119,  860, 3187,  679, 1072, 1064,  117, 2595,\n",
       "          862,  679, 3300,  119,  100,  100, 1064, 2231, 7446,  117, 5928, 5502,\n",
       "         2189, 1064, 3813,  736, 2336,  119, 3198, 1318, 5653, 1064,  711,  686,\n",
       "          117,  760, 1367,  791, 1064, 4324, 6631,  119,  102],\n",
       "        [ 101, 3209, 4127, 2109,  100, 5365, 5350, 7676,  117, 3755, 3755, 3291,\n",
       "         4026, 7392, 2151, 1870,  119, 4904, 7599,  958, 2145, 2157, 1283, 7027,\n",
       "          117, 1915, 7433, 2577,  782, 1921,  671, 3175,  119,  686,  752,  794,\n",
       "          800, 1914,  100,  100,  117, 4495, 3889, 1963, 2769,  771, 1113, 1117,\n",
       "          119,  766, 7557, 1542, 6983, 3867, 7270, 1915,  117,  828, 3457, 7942,\n",
       "         1290, 5312, 3884,  988,  119,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 1921,  677,  862, 1227,  674, 1367, 3217,  117, 1409, 1184, 6443,\n",
       "         3221, 4636, 2399,  782,  119, 7789, 7218, 2213,  100, 7032, 4140, 4177,\n",
       "          117, 2590, 6629, 4310, 2677, 4373, 6776, 2212,  119, 4170, 5428, 5946,\n",
       "         2658, 3102,  679, 2533,  117, 3215, 5755, 3859, 5683, 7023, 3187, 1728,\n",
       "          119, 1377, 2589, 3209, 7262, 3341, 4685, 1403,  117,  862,  849, 2617,\n",
       "         1045, 3308, 1911, 3173,  119,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([[ 101, 4819, 5285, 5021, 2419, 1874, 2798, 2397,  117, 4635, 4373, 3517,\n",
       "          704, 7755, 2347, 2170,  119, 3801, 2226, 2496, 2399, 5468, 7744, 2145,\n",
       "          117, 5825, 5709, 3198, 5688, 4324, 3341, 4692,  119,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 6505, 3482, 2231, 1064, 2552, 3815, 6565,  117, 4373,  100, 6574,\n",
       "         1064, 7032,  868, 1898,  119, 5696, 5900, 1094, 1064, 4324, 4989,  117,\n",
       "          877, 2140, 4466, 1064, 5364, 5290,  119, 5529, 2891, 2891, 1064, 4767,\n",
       "         1351,  117, 3309, 2259, 3241, 1064, 4685, 2127,  119, 4741,  921, 4706,\n",
       "         1064, 5439,  682,  117, 5632, 2552, 4761, 1064, 1780,  719,  119, 2516,\n",
       "         2398, 3787, 1064, 3481, 4895, 4989,  117, 5290, 1501, 5018, 1064, 5384,\n",
       "         4508,  734,  119, 1434,  862, 1628, 1064,  100,  792,  117, 2123,  680,\n",
       "         3734, 1064, 1398, 4619,  119, 4433,  741, 1064, 2340, 1381,  117, 7991,\n",
       "         7911, 1064, 1184, 1400,  119,  100, 7481, 1064, 2286, 2318,  117, 2563,\n",
       "         6241, 1064,  671, 5010,  119, 3805, 2255, 1064, 7478, 1920,  117, 2891,\n",
       "         4767, 1064, 7478, 2207,  119,  860, 3187,  679, 1072, 1064,  117, 2595,\n",
       "          862,  679, 3300,  119,  100,  100, 1064, 2231, 7446,  117, 5928, 5502,\n",
       "         2189, 1064, 3813,  736, 2336,  119, 3198, 1318, 5653, 1064,  711,  686,\n",
       "          117,  760, 1367,  791, 1064, 4324, 6631,  119,  102],\n",
       "        [ 101, 3209, 4127, 2109,  100, 5365, 5350, 7676,  117, 3755, 3755, 3291,\n",
       "         4026, 7392, 2151, 1870,  119, 4904, 7599,  958, 2145, 2157, 1283, 7027,\n",
       "          117, 1915, 7433, 2577,  782, 1921,  671, 3175,  119,  686,  752,  794,\n",
       "          800, 1914,  100,  100,  117, 4495, 3889, 1963, 2769,  771, 1113, 1117,\n",
       "          119,  766, 7557, 1542, 6983, 3867, 7270, 1915,  117,  828, 3457, 7942,\n",
       "         1290, 5312, 3884,  988,  119,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [ 101, 1921,  677,  862, 1227,  674, 1367, 3217,  117, 1409, 1184, 6443,\n",
       "         3221, 4636, 2399,  782,  119, 7789, 7218, 2213,  100, 7032, 4140, 4177,\n",
       "          117, 2590, 6629, 4310, 2677, 4373, 6776, 2212,  119, 4170, 5428, 5946,\n",
       "         2658, 3102,  679, 2533,  117, 3215, 5755, 3859, 5683, 7023, 3187, 1728,\n",
       "          119, 1377, 2589, 3209, 7262, 3341, 4685, 1403,  117,  862,  849, 2617,\n",
       "         1045, 3308, 1911, 3173,  119,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9ce959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:18.502699Z",
     "start_time": "2023-12-25T18:35:18.487739Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4a37cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:18.675239Z",
     "start_time": "2023-12-25T18:35:18.658283Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([4, 165])\n",
      "token_type_ids torch.Size([4, 165])\n",
      "attention_mask torch.Size([4, 165])\n",
      "labels torch.Size([4, 165])\n"
     ]
    }
   ],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be8ebb7",
   "metadata": {},
   "source": [
    "### 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d15b0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:20.987010Z",
     "start_time": "2023-12-25T18:35:20.917196Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, GPT2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20f379be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:25.249423Z",
     "start_time": "2023-12-25T18:35:23.047498Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = AutoModelForCausalLM.from_pretrained('uer/gpt2-chinese-cluecorpussmall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "896e9f43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:29.467142Z",
     "start_time": "2023-12-25T18:35:29.456171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102068736"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参数量\n",
    "sum(i.numel() for i in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "11324a83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:32.939853Z",
     "start_time": "2023-12-25T18:35:32.006350Z"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    out = model(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82092e53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:34.893627Z",
     "start_time": "2023-12-25T18:35:34.882657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9.5183), torch.Size([4, 165, 21128]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['loss'], out['logits'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1becf6d9",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2350b277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:37.002987Z",
     "start_time": "2023-12-25T18:35:36.995008Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75b0f36c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:35:44.087202Z",
     "start_time": "2023-12-25T18:35:44.068253Z"
    }
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    global model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    scheduler = get_scheduler(name='linear',\n",
    "                             num_warmup_steps=0,\n",
    "                             num_training_steps=len(loader),\n",
    "                             optimizer=optimizer)\n",
    "    \n",
    "    model.train()\n",
    "    for i, data in enumerate(loader):\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].to(device)\n",
    "            \n",
    "        out = model(**data)\n",
    "        loss = out['loss']\n",
    "        \n",
    "        loss.backward()\n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            labels = data['labels'][:, 1:]\n",
    "            out = out['logits'].argmax(dim=2)[:, :-1]\n",
    "            select = labels != 0\n",
    "            labels = labels[select]\n",
    "            out = out[select]\n",
    "            del select \n",
    "            \n",
    "            # 计算准确率\n",
    "            accuracy = (labels == out).sum().item() / labels.numel()\n",
    "            lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "            print(i, loss.item(), lr, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15690d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T18:42:05.627065Z",
     "start_time": "2023-12-25T18:35:46.765250Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\.venv\\lib\\site-packages\\transformers\\optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.524815559387207 4.9999343728671184e-05 0.07857142857142857\n",
      "1000 3.04933500289917 4.9343072399853e-05 0.2315270935960591\n",
      "2000 3.7905688285827637 4.868680107103481e-05 0.2193877551020408\n",
      "3000 2.44938588142395 4.8030529742216624e-05 0.20783132530120482\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_84304\\3364925475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_84304\\4162766031.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c8e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# model = model.to('cpu')\n",
    "# torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6d68e13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T19:05:05.520483Z",
     "start_time": "2023-12-25T19:05:05.506521Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate(text, row, col, model):\n",
    "    def generate_loop(data):\n",
    "        with torch.no_grad():\n",
    "            out = model(**data)\n",
    "        \n",
    "        # [5, b, vocab_size]\n",
    "        out = out['logits']\n",
    "        # [5, vocab_size]\n",
    "        out = out[:, -1]\n",
    "        \n",
    "        # [5, vocab_size] -> [5, 50]\n",
    "        topk_value = torch.topk(out, 50).values\n",
    "        # [5, 50], [5] -> [5, 1]\n",
    "        topk_value = topk_value[:, -1].unsqueeze(dim=1)\n",
    "        \n",
    "        # 赋值\n",
    "        out = out.masked_fill(out < topk_value, -float('inf'))\n",
    "        \n",
    "        # 不允许写特殊字符\n",
    "        out[:, tokenizer.sep_token_id] = -float('inf')\n",
    "        out[:, tokenizer.unk_token_id] = -float('inf')\n",
    "        out[:, tokenizer.pad_token_id] = -float('inf')\n",
    "        \n",
    "        for i in '，。':\n",
    "            out[:, tokenizer.get_vocab()[i]] = -float('inf')\n",
    "            \n",
    "        # [5, vocab_size] -> [5, 1]\n",
    "        out = out.softmax(dim=1)\n",
    "        out = out.multinomial(num_samples=1)\n",
    "        \n",
    "        # 强制添加标点符号\n",
    "        c = data['input_ids'].shape[1] / (col + 1)\n",
    "        if c % 1 == 0:\n",
    "            if c % 2 == 0:\n",
    "                out[:, 0] = tokenizer.get_vocab()['。']\n",
    "            else:\n",
    "                out[:, 0] = tokenizer.get_vocab()['，']\n",
    "        \n",
    "        data['input_ids'] = torch.cat([data['input_ids'], out], dim=1)\n",
    "        data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "        data['token_type_ids'] = torch.zeros_like(data['input_ids'])\n",
    "        data['labels'] = data['input_ids'].clone()\n",
    "        \n",
    "        if data['input_ids'].shape[1] >= row * col + row + 1:\n",
    "            return data\n",
    "        return generate_loop(data)\n",
    "    \n",
    "    # 重复三遍\n",
    "    data = tokenizer.batch_encode_plus([text] * 3, return_tensors='pt')\n",
    "    data['input_ids'] = data['input_ids'][:, :-1]\n",
    "    data['attention_mask'] = torch.ones_like(data['input_ids'])\n",
    "    data['token_type_ids'] = torch.zeros_like(data['input_ids'])\n",
    "    data['labels'] = data['input_ids'].clone()\n",
    "    \n",
    "    data = generate_loop(data)\n",
    "    \n",
    "    for i in range(3):\n",
    "        print(i, tokenizer.decode(data['input_ids'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce0c15f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T19:04:44.356816Z",
     "start_time": "2023-12-25T19:04:44.138400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('save.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61afaf5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-25T19:05:46.697299Z",
     "start_time": "2023-12-25T19:05:43.733228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS] 秋 高 气 爽 雁 初 飞 ， 云 树 高 峰 落 叶 稀 。 人 尽 夜 归 山 外 宿 ， 鸡 鸣 霜 月 下 寒 衣 。\n",
      "1 [CLS] 秋 高 气 爽 木 生 秋 ， 何 处 仙 方 未 可 求 。 莫 遣 夜 猿 催 老 去 ， 东 风 吹 老 上 林 丘 。\n",
      "2 [CLS] 秋 高 气 爽 早 蝉 喧 ， 清 籁 无 声 响 自 喧 。 野 望 岂 容 云 梦 见 ， 江 涵 应 属 月 华 昏 。\n"
     ]
    }
   ],
   "source": [
    "generate('秋高气爽', row=4, col=7, model=model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
