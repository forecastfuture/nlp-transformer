{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85c55532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:41:55.770939Z",
     "start_time": "2023-02-16T12:41:54.455456Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2520841e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:46:50.294856Z",
     "start_time": "2023-02-16T12:46:50.212076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x2cf4f74fb08>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义数据集\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, split):\n",
    "        self.datasets = load_from_disk('../data/ChnSentiCorp')\n",
    "        self.dataset = self.datasets[split]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset[i]['text']\n",
    "        label = self.dataset[i]['label']\n",
    "        return text, label\n",
    "    \n",
    "dataset = Dataset('train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b356460f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:46:54.396919Z",
     "start_time": "2023-02-16T12:46:54.377967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 9600\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0a9a9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:51:45.751505Z",
     "start_time": "2023-02-16T12:51:45.733551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89c6956",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:52:01.416658Z",
     "start_time": "2023-02-16T12:52:01.406684Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n",
       " 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8a6a9bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:53:25.813667Z",
     "start_time": "2023-02-16T12:53:17.293451Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='bert-base-chinese', vocab_size=21128, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# 加载字典和分词工具\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf7d57da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T12:59:45.215970Z",
     "start_time": "2023-02-16T12:59:45.204002Z"
    }
   },
   "outputs": [],
   "source": [
    "# 重写collate_fn\n",
    "def collate_fn(data):\n",
    "    sents = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "    \n",
    "    # 编码\n",
    "    data = tokenizer.batch_encode_plus(batch_text_or_text_pairs=sents, \n",
    "                               truncation=True,\n",
    "                               padding='max_length',\n",
    "                               return_tensors='pt',\n",
    "                               return_length='True')\n",
    "    # 编码之后的数字\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "    labels = torch.LongTensor(labels)\n",
    "    \n",
    "    return input_ids, attention_mask, token_type_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56c90dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:01:39.102292Z",
     "start_time": "2023-02-16T13:01:39.017439Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据加载器\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "for i,(input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e903b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:01:49.039140Z",
     "start_time": "2023-02-16T13:01:49.029166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0defcab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:02:59.075502Z",
     "start_time": "2023-02-16T13:02:59.067523Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b72c59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:03:07.890475Z",
     "start_time": "2023-02-16T13:03:07.883472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 512]) torch.Size([16, 512]) torch.Size([16, 512]) tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(input_ids.shape, attention_mask.shape, token_type_ids.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa0870e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:09:22.579330Z",
     "start_time": "2023-02-16T13:05:38.126093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2feb8995cde43808b8795b0e04e2a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\.venv\\lib\\site-packages\\huggingface_hub\\file_download.py:129: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\SupercoldZzz\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# 加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "# 固定bert的参数\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d33acecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:13:34.839581Z",
     "start_time": "2023-02-16T13:13:23.021496Z"
    }
   },
   "outputs": [],
   "source": [
    "# 模型试算\n",
    "out = pretrained(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "699d5cfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:19:07.426440Z",
     "start_time": "2023-02-16T13:19:07.413474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 768])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.last_hidden_state[:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbe4b408",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:21:14.159851Z",
     "start_time": "2023-02-16T13:21:02.312914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义下游任务模型\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, pretrained):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 2)\n",
    "        self.pretrained = pretrained\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "            \n",
    "        out = self.fc(out.last_hidden_state[:, 0])\n",
    "        out = out.softmax(dim=1)\n",
    "        return out\n",
    "    \n",
    "model = Model(pretrained)\n",
    "model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1de6887",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:29:53.325823Z",
     "start_time": "2023-02-16T13:29:53.274959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b202fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:38:00.096326Z",
     "start_time": "2023-02-16T13:38:00.066404Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_117040\\2489896628.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m-> 1186\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Module'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "841199ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:48:53.306084Z",
     "start_time": "2023-02-16T13:45:05.521293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6827474236488342 0.5625\n",
      "5 0.662400484085083 0.625\n",
      "10 0.6865236759185791 0.5625\n",
      "15 0.7083545923233032 0.375\n",
      "20 0.6344900131225586 0.75\n",
      "25 0.658557653427124 0.625\n",
      "30 0.6382225155830383 0.8125\n",
      "35 0.715989351272583 0.375\n",
      "40 0.7118325233459473 0.5\n",
      "45 0.6845795512199402 0.625\n",
      "50 0.685475766658783 0.5\n",
      "55 0.6963281035423279 0.4375\n",
      "60 0.6833534240722656 0.5\n",
      "65 0.6950926780700684 0.4375\n",
      "70 0.72159743309021 0.5\n",
      "75 0.6438045501708984 0.75\n",
      "80 0.7265025973320007 0.3125\n",
      "85 0.7005784511566162 0.5\n",
      "90 0.72879958152771 0.4375\n",
      "95 0.7319801449775696 0.3125\n",
      "100 0.6244087219238281 0.8125\n",
      "105 0.6907938718795776 0.5625\n",
      "110 0.728121817111969 0.4375\n",
      "115 0.6624838709831238 0.5625\n",
      "120 0.6880730986595154 0.5\n",
      "125 0.7138139009475708 0.5\n",
      "130 0.6859719157218933 0.625\n",
      "135 0.6897076964378357 0.5\n",
      "140 0.703993558883667 0.4375\n",
      "145 0.6741662621498108 0.625\n",
      "150 0.6896845102310181 0.5625\n",
      "155 0.6807734966278076 0.5\n",
      "160 0.6992517709732056 0.375\n",
      "165 0.6861604452133179 0.5625\n",
      "170 0.6964953541755676 0.5\n",
      "175 0.7046523690223694 0.375\n",
      "180 0.6964455246925354 0.5625\n",
      "185 0.6678289771080017 0.6875\n",
      "190 0.7207179069519043 0.5\n",
      "195 0.6811145544052124 0.5\n",
      "200 0.6888732314109802 0.6875\n",
      "205 0.6668736934661865 0.6875\n",
      "210 0.7156791090965271 0.5625\n",
      "215 0.6632345914840698 0.6875\n",
      "220 0.6545792818069458 0.625\n",
      "225 0.6516266465187073 0.625\n",
      "230 0.7161979675292969 0.3125\n",
      "235 0.6942268013954163 0.5\n",
      "240 0.6702930331230164 0.625\n",
      "245 0.681835949420929 0.5625\n",
      "250 0.6935969591140747 0.5625\n",
      "255 0.6608825922012329 0.5625\n",
      "260 0.6685808897018433 0.6875\n",
      "265 0.671800971031189 0.5625\n",
      "270 0.6797905564308167 0.5\n",
      "275 0.6784118413925171 0.6875\n",
      "280 0.7256955504417419 0.3125\n",
      "285 0.6514056324958801 0.5625\n",
      "290 0.677427351474762 0.625\n",
      "295 0.673608124256134 0.625\n",
      "300 0.627325713634491 0.875\n",
      "305 0.6832352876663208 0.625\n",
      "310 0.6946585774421692 0.5625\n",
      "315 0.7090035080909729 0.4375\n",
      "320 0.6391682624816895 0.75\n",
      "325 0.6838541030883789 0.4375\n",
      "330 0.656248152256012 0.625\n",
      "335 0.6501436233520508 0.75\n",
      "340 0.6998576521873474 0.5\n",
      "345 0.6810024976730347 0.5\n",
      "350 0.6962616443634033 0.4375\n",
      "355 0.7006884813308716 0.5625\n",
      "360 0.6905456185340881 0.5625\n",
      "365 0.7122035026550293 0.5\n",
      "370 0.6481106877326965 0.75\n",
      "375 0.6496854424476624 0.625\n",
      "380 0.7238764762878418 0.4375\n",
      "385 0.690892219543457 0.4375\n",
      "390 0.7305709719657898 0.4375\n",
      "395 0.675710141658783 0.5\n",
      "400 0.699824869632721 0.5\n",
      "405 0.7247074842453003 0.5\n",
      "410 0.6779544353485107 0.5625\n",
      "415 0.644871711730957 0.75\n",
      "420 0.746654212474823 0.3125\n",
      "425 0.6142871975898743 0.75\n",
      "430 0.7145064473152161 0.5625\n",
      "435 0.7231141924858093 0.4375\n",
      "440 0.6442602872848511 0.8125\n",
      "445 0.6833810806274414 0.5\n",
      "450 0.6868219375610352 0.4375\n",
      "455 0.6882677674293518 0.4375\n",
      "460 0.6954501867294312 0.5\n",
      "465 0.655935525894165 0.625\n",
      "470 0.7108137011528015 0.5625\n",
      "475 0.714965283870697 0.5\n",
      "480 0.7043062448501587 0.5\n",
      "485 0.6811400651931763 0.5\n",
      "490 0.6790148615837097 0.5625\n",
      "495 0.7045982480049133 0.5625\n",
      "500 0.6922914385795593 0.5625\n",
      "505 0.6716947555541992 0.625\n",
      "510 0.7021215558052063 0.5\n",
      "515 0.7055610418319702 0.4375\n",
      "520 0.7127469778060913 0.5\n",
      "525 0.6986604928970337 0.375\n",
      "530 0.6980202198028564 0.5\n",
      "535 0.6864044666290283 0.625\n",
      "540 0.6674137711524963 0.6875\n",
      "545 0.6921521425247192 0.5625\n",
      "550 0.6969794631004333 0.5625\n",
      "555 0.7162293791770935 0.4375\n",
      "560 0.6457531452178955 0.625\n",
      "565 0.7018555998802185 0.5\n",
      "570 0.69266277551651 0.625\n",
      "575 0.6665578484535217 0.6875\n",
      "580 0.680888831615448 0.5625\n",
      "585 0.6789348125457764 0.625\n",
      "590 0.7014723420143127 0.4375\n",
      "595 0.7267574071884155 0.375\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "# 训练\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model = Model(pretrained)\n",
    "model.train()\n",
    "model.to(device)\n",
    "for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader):\n",
    "    \n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    token_type_ids = token_type_ids.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    out = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "    loss = criterion(out, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        out = out.argmax(dim=1)\n",
    "        accuracy = (out == labels).sum().item() / len(labels)\n",
    "        print(i, loss.item(), accuracy)\n",
    "        \n",
    "    if i == 600:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce31b5d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-16T13:53:00.044775Z",
     "start_time": "2023-02-16T13:52:56.057443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "0.58125\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    loader_test = torch.utils.data.DataLoader(dataset=Dataset('validation'),\n",
    "                                             batch_size=32,\n",
    "                                             collate_fn=collate_fn,\n",
    "                                             shuffle=True,\n",
    "                                             drop_last=True)\n",
    "    for i, (input_ids, attention_mask, token_type_ids, labels) in enumerate(loader_test):\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        if i == 5:\n",
    "            break\n",
    "        print(i)\n",
    "        with torch.no_grad():\n",
    "            out = model(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids)\n",
    "        out = out.argmax(dim=1)\n",
    "        correct += (out==labels).sum().item()\n",
    "        total += len(labels)\n",
    "    print(correct / total)\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
